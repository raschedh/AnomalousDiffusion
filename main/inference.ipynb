{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Inference for both challenge format and general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.padding import pad_batch, FEATURE_PADDING_VALUE, LABEL_PADDING_VALUE, pad_tensor\n",
    "from utils.features import getFeatures\n",
    "from models.models import ClassificationModel, RegressionModel\n",
    "import statistics\n",
    "from utils.postprocessing import combined_cps_k_focused\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from pathlib import Path\n",
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('The model is running on:', DEVICE) \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "AlphaModel = RegressionModel().to(DEVICE)\n",
    "KModel = RegressionModel().to(DEVICE)\n",
    "StateModel = ClassificationModel().to(DEVICE)\n",
    "\n",
    "AlphaModel.load_state_dict(torch.load(\"models/optimal_weights/alpha_weights\"))\n",
    "KModel.load_state_dict(torch.load(\"models/optimal_weights/k_weights\"))\n",
    "StateModel.load_state_dict(torch.load(\"models/optimal_weights/state_weights\"))\n",
    "\n",
    "AlphaModel.eval()\n",
    "KModel.eval()\n",
    "StateModel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General \n",
    "\n",
    "For plotting and extracting time series, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_FILE = \"<data as .pkl dataloader class in torch>\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(PICKLE_FILE, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "SAVE_DIR, _ = os.path.split(PICKLE_FILE)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(\"Saving to dir:\", SAVE_DIR)\n",
    "\n",
    "concat_data = ConcatDataset(data)\n",
    "dataloader = DataLoader(concat_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_batch)\n",
    "print(\"Test data: \", len(data), \"DataLoader Sizes:\", len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for stacking\n",
    "pred_a_list, pred_k_list, pred_state_list = [], [], []\n",
    "gt_a_list, gt_k_list, gt_state_list = [], [], []\n",
    "\n",
    "progress_bar = tqdm(total=len(dataloader), desc='Testing', position=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, alpha_labels, k_labels, state_labels in dataloader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        \n",
    "        # Get predictions\n",
    "        pred_alpha_per_track = AlphaModel(inputs).squeeze(-1)\n",
    "        pred_k_per_track = KModel(inputs).squeeze(-1)\n",
    "        pred_state_per_track = torch.argmax(StateModel(inputs), dim=-1)\n",
    "\n",
    "        # Pad predictions before appending\n",
    "        pred_a_list.append(pad_tensor(pred_alpha_per_track))\n",
    "        pred_k_list.append(pad_tensor(pred_k_per_track))\n",
    "        pred_state_list.append(pad_tensor(pred_state_per_track))\n",
    "\n",
    "        # Append ground truth (do not pad ground truth)\n",
    "        gt_a_list.append(alpha_labels)\n",
    "        gt_k_list.append(k_labels)\n",
    "        gt_state_list.append(state_labels)\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the lists into tensors\n",
    "pred_a = torch.cat(pred_a_list, dim=0)\n",
    "pred_k = torch.cat(pred_k_list, dim=0)\n",
    "pred_state = torch.cat(pred_state_list, dim=0)\n",
    "\n",
    "gt_a = torch.cat(gt_a_list, dim=0)\n",
    "gt_k = torch.cat(gt_k_list, dim=0)\n",
    "gt_state = torch.cat(gt_state_list, dim=0)\n",
    "\n",
    "print(\"Predictions shape:\", pred_k.shape)\n",
    "print(\"Ground truth shape:\", gt_k.shape)\n",
    "\n",
    "# Convert to numpy and save\n",
    "print(\"Converting to numpy and saving...\")\n",
    "np.save(os.path.join(SAVE_DIR, \"pred_a.npy\"), pred_a.cpu().numpy())\n",
    "np.save(os.path.join(SAVE_DIR, \"pred_k.npy\"), pred_k.cpu().numpy())\n",
    "np.save(os.path.join(SAVE_DIR, \"pred_state.npy\"), pred_state.cpu().numpy())\n",
    "np.save(os.path.join(SAVE_DIR, \"gt_a.npy\"), gt_a.cpu().numpy())\n",
    "np.save(os.path.join(SAVE_DIR, \"gt_k.npy\"), gt_k.cpu().numpy())\n",
    "np.save(os.path.join(SAVE_DIR, \"gt_state.npy\"), gt_state.cpu().numpy())\n",
    "print(\"Processing completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For challenge format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict on inputs tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(df, max_size=200):\n",
    "\n",
    "    \"\"\"\n",
    "    Created predictions on alpha, k, and state values for a given input series and detects changepoints.\n",
    "    This function is specifically designed for the challenge.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the input series.\n",
    "        max_size (int): The maximum size of the input series. Default\n",
    "\n",
    "    Returns:\n",
    "        final_predictions (list): A list containing the predicted alpha, k, and state values along with the changepoints.\n",
    "    \"\"\"\n",
    "\n",
    "    features = np.nan_to_num(getFeatures(df[\"x\"].values, df[\"y\"].values), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    features = torch.tensor(features, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "    length = features.size(1)\n",
    "\n",
    "    if length < max_size:\n",
    "        features = F.pad(features, (0, 0, 0, max_size - length), value=FEATURE_PADDING_VALUE)\n",
    "    elif length > max_size:\n",
    "        features = features[:, :max_size]\n",
    "        print(f\"Note that the input series is longer than the maximum size. The input series has been truncated to the first {max_size} values.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # convert to numpy arrays for downstream analysis\n",
    "        pred_alpha_list = AlphaModel(features).cpu().numpy().flatten().squeeze()[:length]\n",
    "        pred_k_list = KModel(features).cpu().numpy().flatten().squeeze()[:length]\n",
    "        states_log_probs = StateModel(features)\n",
    "        pred_states_list = torch.argmax(states_log_probs, dim=-1).cpu().numpy().flatten().squeeze()[:length]\n",
    "\n",
    "    merged_cps, _, _, pred_alpha_list, pred_k_list, pred_states_list = combined_cps_k_focused(pred_alpha_list, pred_k_list, pred_states_list)\n",
    "    final_predictions = []\n",
    "    merged_cps = [0] + merged_cps\n",
    "\n",
    "    for i in range(len(merged_cps) - 1):\n",
    "        \n",
    "        start = merged_cps[i]\n",
    "        end = merged_cps[i + 1]\n",
    "        \n",
    "        log_k_plus1 = np.mean(pred_k_list[start:end])\n",
    "        final_alpha = np.mean(pred_alpha_list[start:end])\n",
    "        final_state = statistics.mode(pred_states_list[start:end])\n",
    "\n",
    "        final_k = 10**log_k_plus1 - 1     \n",
    "\n",
    "        if final_k >  0.1 and final_state == 0:\n",
    "            final_state = 2\n",
    "\n",
    "        final_predictions.append(final_k)\n",
    "        final_predictions.append(final_alpha)\n",
    "        final_predictions.append(int(final_state))\n",
    "        final_predictions.append(end)\n",
    "\n",
    "    return final_predictions, pred_alpha_list, pred_k_list, pred_states_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_data_path = \"<path to track 2>\"\n",
    "\n",
    "N_EXP = 9\n",
    "N_FOVS = 30\n",
    "track = 2\n",
    "\n",
    "path_results = 'new_scoring/res/'\n",
    "path_track = os.path.join(path_results, f'track_{track}/')\n",
    "\n",
    "os.makedirs(path_results, exist_ok=True)\n",
    "os.makedirs(path_track, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in range(1, N_EXP + 1):\n",
    "    \n",
    "    path_exp = os.path.join(path_track, f'exp_{exp}/')\n",
    "    os.makedirs(path_exp, exist_ok=True)\n",
    "    \n",
    "    for fov in range(N_FOVS):\n",
    "\n",
    "        df = pd.read_csv(challenge_data_path+f'/exp_{exp}/trajs_fov_{fov}.csv')\n",
    "\n",
    "        traj_idx = df.traj_idx.unique()\n",
    "        \n",
    "        submission_file = os.path.join(path_exp, f'fov_{fov}.txt')\n",
    "        \n",
    "        with open(submission_file, 'a') as f:\n",
    "            for idx in traj_idx:\n",
    "                \n",
    "                sub_df = df[df.traj_idx == idx]  \n",
    "\n",
    "                pred, _, _, _ =  getPredictions(sub_df)\n",
    "\n",
    "                prediction_final = [idx.astype(int)] + pred\n",
    "                formatted_numbers = ','.join(map(str, prediction_final))\n",
    "                \n",
    "                f.write(formatted_numbers + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison to reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andi_datasets.utils_challenge import codalab_scoring\n",
    "\n",
    "input_dir = \"new_scoring\"\n",
    "output_dir = \"new_scoring\"\n",
    "\n",
    "codalab_scoring(INPUT_DIR = input_dir, OUTPUT_DIR = output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_data_path = \"/home/haidiri/Desktop/AnDiChallenge2024/benchmark_andi_track_2/track_2\"\n",
    "\n",
    "N_EXP = 9\n",
    "N_FOVS = 30\n",
    "track = 2\n",
    "\n",
    "gt_a, gt_k, gt_state = [], [], []\n",
    "pred_a, pred_k, pred_state = [], [], []\n",
    "x_coor, y_coor = [], []\n",
    "\n",
    "for exp in [2]:    \n",
    "    for fov in range(N_FOVS):\n",
    "        print(fov, end=\"\\r\")\n",
    "        df = pd.read_csv(challenge_data_path+f'/exp_{exp}/trajs_fov_{fov}.csv')\n",
    "        traj_idx = df.traj_idx.unique()\n",
    "\n",
    "        for idx in traj_idx:\n",
    "            sub_df = df[df.traj_idx == idx]  \n",
    "            _, pa, pk, ps =  getPredictions(sub_df)\n",
    "\n",
    "            pred_a.append(pa)\n",
    "            pred_k.append(pk)\n",
    "            pred_state.append(ps)\n",
    "\n",
    "            gt_a.append(sub_df[\"alpha\"].values)\n",
    "            gt_k.append(sub_df[\"D\"].values)\n",
    "            gt_state.append(sub_df[\"state\"].values)\n",
    "\n",
    "            x_coor.append(sub_df[\"x\"])\n",
    "            y_coor.append(sub_df[\"y\"])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 66\n",
    "\n",
    "plt.plot(x_coor[INDEX], y_coor[INDEX])\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter([i for i in range(len(pred_a[INDEX]))], pred_a[INDEX], color=\"red\")\n",
    "plt.scatter([i for i in range(len(gt_a[INDEX]))], gt_a[INDEX], color=\"blue\")\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter([i for i in range(len(pred_state[INDEX]))], pred_state[INDEX], color=\"red\")\n",
    "plt.scatter([i for i in range(len(gt_state[INDEX]))], gt_state[INDEX], color=\"blue\")\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter([i for i in range(len(pred_k[INDEX]))], pred_k[INDEX], color=\"red\")\n",
    "plt.scatter([i for i in range(len(gt_k[INDEX]))], gt_k[INDEX], color=\"blue\")\n",
    "print(np.unique(gt_k[INDEX]), np.unique(gt_a[INDEX]))\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
