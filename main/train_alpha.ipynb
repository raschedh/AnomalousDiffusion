{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is running on: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.nn as nn \n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "from utils.padding import pad_batch, LABEL_PADDING_VALUE\n",
    "from models.models import RegressionModel\n",
    "import pickle \n",
    "from pathlib import Path\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 35\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 2e-6\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print('The model is running on:', DEVICE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_tracks_directory = Path(\"<enter dir filepath that has train val and test data>\")\n",
    "\n",
    "# for faster training we use pickled data, implementation without pickle see commented below\n",
    "train_files = list(simulated_tracks_directory.glob(\"*/train_instances.pkl\"))\n",
    "val_files = list(simulated_tracks_directory.glob(\"*/val_instances.pkl\"))\n",
    "test_files = list(simulated_tracks_directory.glob(\"*/test_instances.pkl\"))\n",
    "\n",
    "train_instances = []\n",
    "val_instances = []\n",
    "test_instances = []\n",
    "\n",
    "for file in train_files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        train_instances += pickle.load(f)\n",
    "\n",
    "for file in val_files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        val_instances += pickle.load(f)\n",
    "\n",
    "for file in test_files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        test_instances += pickle.load(f)\n",
    "\n",
    "print(\"Train data: \", len(train_instances), \"Test data: \", len(test_instances), \"Val data: \", len(val_instances))\n",
    "\n",
    "# filepaths = list(simulated_tracks_directory.rglob('*.parquet'))\n",
    "# print(\"Number of files found:\", len(filepaths))\n",
    "# random.shuffle(filepaths)\n",
    "# train_instances = [TimeSeriesDataset(filepath, augment=True) for filepath in filepaths[:int(len(filepaths)*0.7)]]\n",
    "# test_instances = [TimeSeriesDataset(filepath, augment=False) for filepath in filepaths[int(len(filepaths)*0.7):int(len(filepaths)*0.85)]]\n",
    "# val_instances = [TimeSeriesDataset(filepath, augment=False) for filepath in filepaths[int(len(filepaths)*0.85):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_train = ConcatDataset(train_instances)\n",
    "conc_val = ConcatDataset(val_instances)\n",
    "conc_test = ConcatDataset(test_instances)\n",
    "\n",
    "train_loader = DataLoader(conc_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "test_loader = DataLoader(conc_test, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "val_loader = DataLoader(conc_val, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "\n",
    "print(\"DataLoader Sizes:\", len(train_loader), len(test_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Load the model, optimizer, scheduler, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel().to(DEVICE)\n",
    "print(summary(model, input_size=(BATCH_SIZE, 200, 10)))\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('models/checkpoints/alpha_runs/runs_{}'.format(timestamp))\n",
    "model_directory = os.path.join('models/checkpoints/alpha_model', 'model_{}'.format(timestamp))\n",
    "\n",
    "continuous_loss_fn = nn.L1Loss(reduction='none')\n",
    "best_val_loss = float(\"inf\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    runs = 0\n",
    "\n",
    "    for inputs, alpha_labels,_,_ in dataloader:\n",
    "\n",
    "        inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "        mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.item()\n",
    "        runs += 1\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "    return running_loss/runs\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    running_val_total = 0.0\n",
    "    val_runs = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, alpha_labels,_,_ in dataloader:\n",
    "            \n",
    "            inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "            mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "            \n",
    "            outputs = model(inputs)  \n",
    "            outputs = outputs.squeeze(-1)\n",
    "            total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()            \n",
    "            running_val_total += total_loss.item()\n",
    "            val_runs += 1\n",
    "    \n",
    "    return running_val_total / val_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_directory, exist_ok=True)\n",
    "# model.load_state_dict(torch.load('/home/haidiri/Desktop/AnDiChallenge2024/models/checkpoints/alpha_model/model_20241025_132405/model_2'))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    progress_bar = tqdm(total=len(train_loader), desc='Training', position=0)\n",
    "\n",
    "    avg_training_loss = train_one_epoch(model, optimizer, train_loader)\n",
    "    val_total_loss  = evaluate_model(model, val_loader)\n",
    "    \n",
    "    print(f'Training LOSS: Alpha {avg_training_loss}\\n'\n",
    "          f'Validation LOSS: Alpha {val_total_loss} \\n')\n",
    "    \n",
    "    writer.add_scalars('Losses', {\n",
    "        'Training Alpha Loss': avg_training_loss,\n",
    "        'Validation Alpha Loss': val_total_loss,\n",
    "        }, epoch + 1)\n",
    "\n",
    "    writer.flush()\n",
    "    \n",
    "    if val_total_loss < best_val_loss:\n",
    "        best_val_loss = val_total_loss\n",
    "        best_model_path = os.path.join(model_directory, f'model_{epoch + 1}')\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    scheduler.step(val_total_loss)\n",
    "    \n",
    "progress_bar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Validation Loss:\", best_val_loss)\n",
    "print(\"Best Model Path\", best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = RegressionModel().to(DEVICE)\n",
    "model.load_state_dict(torch.load('<best train file>'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_test_total = 0.0\n",
    "test_runs = 0.0\n",
    "\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "progress_bar = tqdm(total=len(test_loader), desc='Testing', position=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, alpha_labels,_,_ in test_loader:\n",
    "        \n",
    "        inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "\n",
    "        mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "        outputs = model(inputs).squeeze(-1)\n",
    "        total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()\n",
    "        \n",
    "        running_test_total += total_loss.item()\n",
    "        test_runs += 1\n",
    "\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        ground_truth.extend(alpha_labels.cpu().numpy())\n",
    "        progress_bar.update()\n",
    "\n",
    "\n",
    "# Calculate average losses\n",
    "avg_test_loss = running_test_total / test_runs\n",
    "print(f'Average test loss: {avg_test_loss}')\n",
    "progress_bar.close()\n",
    "\n",
    "# Average test loss: 0.11042290411644512 with normal weights\n",
    "# Average test loss: 0.11053658076882363 with alpha fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 0\n",
    "padding_starts = (ground_truth[INDEX] == LABEL_PADDING_VALUE).argmax() \n",
    "\n",
    "if padding_starts == 0:\n",
    "    padding_starts = 200\n",
    "\n",
    "pred_alpha = predictions[INDEX][:padding_starts]\n",
    "true_alpha = ground_truth[INDEX][:padding_starts]\n",
    "time = [i for i in range(padding_starts)]\n",
    "\n",
    "print((pred_alpha - true_alpha).abs().mean())   \n",
    "plt.scatter(time, pred_alpha, color=\"red\")\n",
    "plt.scatter(time, true_alpha, color=\"blue\")\n",
    "plt.title(\"Alpha Predictions\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
