{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.nn as nn \n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from utils.timeseriesdataset import TimeSeriesDataset\n",
    "from utils.pad_batch import pad_batch, LABEL_PADDING_VALUE\n",
    "from models.RegressionModel import RegressionModel\n",
    "import pickle \n",
    "from pathlib import Path\n",
    "from utils.load_data import load_data\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 35\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 2e-6\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print('The model is running on:', DEVICE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances = []\n",
    "val_instances = []\n",
    "test_instances = []\n",
    "\n",
    "train_files = list(Path(\"../data/simulated_tracks\").glob(\"*/train_instances.pkl\"))\n",
    "val_files = list(Path(\"../data/simulated_tracks\").glob(\"*/val_instances.pkl\"))\n",
    "test_files = list(Path(\"../data/simulated_tracks\").glob(\"*/test_instances.pkl\"))\n",
    "\n",
    "for file in train_files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        train_instances += pickle.load(f)\n",
    "\n",
    "for file in val_files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        val_instances += pickle.load(f)\n",
    "\n",
    "for file in test_files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        test_instances += pickle.load(f)\n",
    "\n",
    "print(\"Train data: \", len(train_instances), \"Test data: \", len(test_instances), \"Val data: \", len(val_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_train = ConcatDataset(train_instances)\n",
    "conc_val = ConcatDataset(val_instances)\n",
    "conc_test = ConcatDataset(test_instances)\n",
    "\n",
    "train_loader = DataLoader(conc_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "test_loader = DataLoader(conc_test, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "val_loader = DataLoader(conc_val, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "\n",
    "print(\"DataLoader Sizes:\", len(train_loader), len(test_loader), len(val_loader))\n",
    "\n",
    "# DATA_PATH = \"../data/simulated_tracks\"\n",
    "# filepaths = list(Path(DATA_PATH).rglob('*.parquet'))\n",
    "# random.shuffle(filepaths)\n",
    "\n",
    "# print(\"Number of files found:\", len(filepaths))\n",
    "\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "# val_data = []\n",
    "\n",
    "# train_data = [TimeSeriesDataset(filepath, augment=True) for filepath in filepaths[:int(len(filepaths)*0.7)]]\n",
    "# test_data = [TimeSeriesDataset(filepath, augment=False) for filepath in filepaths[int(len(filepaths)*0.7):int(len(filepaths)*0.85)]]\n",
    "# val_data = [TimeSeriesDataset(filepath, augment=False) for filepath in filepaths[int(len(filepaths)*0.85):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = load_data() \n",
    "\n",
    "print(\"Train data: \", len(train_data))\n",
    "print(\"Val data: \", len(val_data))\n",
    "\n",
    "conc_train = ConcatDataset(train_data)\n",
    "conc_val = ConcatDataset(val_data)\n",
    "\n",
    "training_loader = DataLoader(conc_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "val_loader = DataLoader(conc_val, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "\n",
    "print(\"Data\", len(training_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Load the model, optimizer, scheduler, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel().to(DEVICE)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('models/checkpoints/alpha_runs/runs_{}'.format(timestamp))\n",
    "model_directory = os.path.join('models/checkpoints/alpha_model', 'model_{}'.format(timestamp))\n",
    "\n",
    "print(summary(model, input_size=(BATCH_SIZE, 200, 10)))\n",
    "\n",
    "continuous_loss_fn = nn.L1Loss(reduction='none')\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=2e-6)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    runs = 0\n",
    "\n",
    "    for inputs, alpha_labels,_,_ in dataloader:\n",
    "\n",
    "        inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "        mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.item()\n",
    "        runs += 1\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "    return running_loss/runs\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    running_val_total = 0.0\n",
    "    val_runs = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, alpha_labels,_,_ in dataloader:\n",
    "            \n",
    "            inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "            mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "            \n",
    "            outputs = model(inputs)  \n",
    "            outputs = outputs.squeeze(-1)\n",
    "            total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()            \n",
    "            running_val_total += total_loss.item()\n",
    "            val_runs += 1\n",
    "    \n",
    "    return running_val_total / val_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_directory, exist_ok=True)\n",
    "# model.load_state_dict(torch.load('/home/haidiri/Desktop/AnDiChallenge2024/models/checkpoints/alpha_model/model_20241025_132405/model_2'))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    progress_bar = tqdm(total=len(training_loader), desc='Training', position=0)\n",
    "\n",
    "    avg_training_loss = train_one_epoch(model, optimizer, training_loader)\n",
    "    val_total_loss  = evaluate_model(model, val_loader)\n",
    "    \n",
    "    print(f'Training LOSS: Alpha {avg_training_loss}\\n'\n",
    "          f'Validation LOSS: Alpha {val_total_loss} \\n')\n",
    "    \n",
    "    writer.add_scalars('Losses', {\n",
    "        'Training Alpha Loss': avg_training_loss,\n",
    "        'Validation Alpha Loss': val_total_loss,\n",
    "        }, epoch + 1)\n",
    "\n",
    "    writer.flush()\n",
    "    \n",
    "    if val_total_loss < best_val_loss:\n",
    "        best_val_loss = val_total_loss\n",
    "        best_model_path = os.path.join(model_directory, f'model_{epoch + 1}')\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    scheduler.step(val_total_loss)\n",
    "    \n",
    "progress_bar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Validation Loss:\", best_val_loss)\n",
    "print(\"Best Model Path\", best_model_path)\n",
    "#  models/checkpoints/alpha_model/model_20241027_120020/model_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RegressionModel().to(DEVICE)\n",
    "# # model.load_state_dict(torch.load('/home/haidiri/Desktop/AnDiChallenge2024/models/optimal_weights/alpha_weights'))\n",
    "# model.load_state_dict(torch.load('/home/haidiri/Desktop/AnDiChallenge2024/models/checkpoints/alpha_model/model_20241026_150827/model_9'))\n",
    "# # models/checkpoints/alpha_model/model_20241026_150827/model_9\n",
    "# model.eval()\n",
    "\n",
    "# running_test_total = 0.0\n",
    "# test_runs = 0.0\n",
    "\n",
    "# predictions = []\n",
    "# ground_truth = []\n",
    "\n",
    "# progress_bar = tqdm(total=len(val_loader), desc='Testing', position=0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for inputs, alpha_labels,_,_ in val_loader:\n",
    "        \n",
    "#         inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "\n",
    "#         mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "#         outputs = model(inputs).squeeze(-1)\n",
    "#         total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()\n",
    "        \n",
    "#         running_test_total += total_loss.item()\n",
    "#         test_runs += 1\n",
    "\n",
    "#         predictions.extend(outputs.cpu().numpy())\n",
    "#         ground_truth.extend(alpha_labels.cpu().numpy())\n",
    "#         progress_bar.update()\n",
    "\n",
    "\n",
    "# # Calculate average losses\n",
    "# avg_test_loss = running_test_total / test_runs\n",
    "# print(f'Average test loss: {avg_test_loss}')\n",
    "# progress_bar.close()\n",
    "\n",
    "# Testing: 100%|██████████| 57094/57094 [13:21<00:00, 71.25it/s]\n",
    "# non finetuned model\n",
    "# Average test loss: 0.11597597394306262"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/haidiri/Desktop/AnDiChallenge2024/data/simulated_tracks/simulations_general/test_instances.pkl\", \"rb\") as file:\n",
    "    test_data = pickle.load(file)\n",
    "\n",
    "with open(\"/home/haidiri/Desktop/AnDiChallenge2024/data/simulated_tracks/simulations_3bias/test_instances.pkl\", \"rb\") as file:\n",
    "    test_data.extend(pickle.load(file))\n",
    "\n",
    "with open(\"/home/haidiri/Desktop/AnDiChallenge2024/data/simulated_tracks/simulations_default/test_instances.pkl\", \"rb\") as file:\n",
    "    test_data.extend(pickle.load(file))\n",
    "\n",
    "# with open(\"/home/haidiri/Desktop/AnDiChallenge2024/data/simulated_tracks/simulation_alpha_K_one_fixed/test_instances.pkl\", \"rb\") as file:\n",
    "#     test_data.extend(pickle.load(file))\n",
    "\n",
    "conc_test = ConcatDataset(test_data)\n",
    "test_loader = DataLoader(conc_test, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel().to(DEVICE)\n",
    "model.load_state_dict(torch.load('/home/haidiri/Desktop/AnDiChallenge2024/models/optimal_weights/alpha_weights_with_fixed'))\n",
    "# model.load_state_dict(torch.load('/home/haidiri/Desktop/AnDiChallenge2024/src/models/checkpoints/alpha_model/model_20241026_150827/model_9'))\n",
    "# models/checkpoints/alpha_model/model_20241026_150827/model_9\n",
    "model.eval()\n",
    "\n",
    "running_test_total = 0.0\n",
    "test_runs = 0.0\n",
    "\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "progress_bar = tqdm(total=len(test_loader), desc='Testing', position=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, alpha_labels,_,_ in test_loader:\n",
    "        \n",
    "        inputs, alpha_labels = inputs.to(DEVICE), alpha_labels.to(DEVICE)\n",
    "\n",
    "        mask = (alpha_labels != LABEL_PADDING_VALUE).float()\n",
    "        outputs = model(inputs).squeeze(-1)\n",
    "        total_loss = (continuous_loss_fn(outputs, alpha_labels) * mask).sum() / mask.sum()\n",
    "        \n",
    "        running_test_total += total_loss.item()\n",
    "        test_runs += 1\n",
    "\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        ground_truth.extend(alpha_labels.cpu().numpy())\n",
    "        progress_bar.update()\n",
    "\n",
    "\n",
    "# Calculate average losses\n",
    "avg_test_loss = running_test_total / test_runs\n",
    "print(f'Average test loss: {avg_test_loss}')\n",
    "progress_bar.close()\n",
    "\n",
    "# Average test loss: 0.11042290411644512 with normal weights\n",
    "# Average test loss: 0.11053658076882363 with alpha fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 0\n",
    "import numpy as np\n",
    "padding_starts = (ground_truth[INDEX] == LABEL_PADDING_VALUE).argmax() \n",
    "\n",
    "if padding_starts == 0:\n",
    "    padding_starts = 200\n",
    "\n",
    "pred_alpha = predictions[INDEX][:padding_starts]\n",
    "true_alpha = ground_truth[INDEX][:padding_starts]\n",
    "print(np.abs(pred_alpha - true_alpha).mean())   \n",
    "\n",
    "plt.scatter([i for i in range(len(pred_alpha))], pred_alpha, color=\"red\")\n",
    "plt.scatter([i for i in range(len(true_alpha))], true_alpha, color=\"blue\")\n",
    "plt.title(\"Alpha\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gapseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
